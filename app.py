# app.py: C√ìDIGO FINAL E EST√ÅVEL PARA STREAMLIT
# Substitua TODO o seu arquivo app.py por este c√≥digo.

import os
import streamlit as st
from supabase.client import Client, create_client
from google import genai
from google.genai.errors import APIError
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente (para teste local)
load_dotenv()

# --------------------------------------------------------------------------
# 1. CONFIGURA√á√ïES E CHAVES (Leitura do Streamlit Secrets)
# Usamos try/except para tentar ler as chaves que voc√™ configurou
# --------------------------------------------------------------------------

# Tenta ler as chaves em MAI√öSCULAS e MIN√öSCULAS
try:
    GEMINI_API_KEY_SECRET = st.secrets.get("gemini_api_key") or st.secrets["GEMINI_API_KEY"]
    SUPABASE_URL = st.secrets.get("supabase_url") or st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets.get("supabase_key") or st.secrets["SUPABASE_KEY"]
except KeyError:
    # Se der erro no secrets, tenta ler as vari√°veis de ambiente (para teste local)
    GEMINI_API_KEY_SECRET = os.environ.get("GEMINI_API_KEY") 
    SUPABASE_URL = os.environ.get("SUPABASE_URL") 
    SUPABASE_KEY = os.environ.get("SUPABASE_KEY") 
    
if not GEMINI_API_KEY_SECRET or not SUPABASE_URL:
    st.error("Erro: As chaves de API (GEMINI/SUPABASE) n√£o foram configuradas corretamente nos Streamlit Secrets.")
    st.stop()

# Define a vari√°vel de ambiente (necess√°ria para o cliente Gemini)
os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY_SECRET
TABLE_NAME = "champlim"


# --------------------------------------------------------------------------
# 2. CLIENTES E EMBEDDER (Usando o Cliente Puro do Google)
# --------------------------------------------------------------------------
@st.cache_resource
def initialize_clients():
    supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # Inicializa o cliente Google com a chave lida (muito mais est√°vel)
    gemini_client = genai.Client(api_key=GEMINI_API_KEY_SECRET)
    
    return supabase_client, gemini_client

supabase, gemini_client = initialize_clients()


# --------------------------------------------------------------------------
# 3. FUN√á√ÉO DE BUSCA RAG (L√≥gica Final Est√°vel)
# --------------------------------------------------------------------------
def ask_rag(query):
    
    # 1. CRIA√á√ÉO DO EMBEDDING (Substitui o HuggingFace)
    try:
        embedding_response = gemini_client.models.embed_content(
            model='models/embedding-001', 
            content=query
        )
        # O formato da resposta √© ligeiramente diferente do HuggingFace
        query_vector = embedding_response['embedding']
    except APIError as e:
        return f"Erro na API do Google ao criar o vetor de busca: {e}"


    # 2. CHAMADA RPC AO SUPABASE (Busca Vetorial k=40)
    rpc_params = {
        'query_embedding': query_vector,
        'match_count': 40  # K=40, o valor est√°vel para o free tier
    }
    response = supabase.rpc('vector_search', rpc_params).execute()

    context = ""
    if response.data:
        for item in response.data:
            metadata = item.get('metadata', {})
            page = metadata.get('page')
            
            # Fonte CORRIGIDA: Lendo a coluna 'file_name' (que corrigimos no SQL)
            file_name_col = item.get('file_name', 'R. N. Champlin - Enciclop√©dia')
            
            source = f" (Fonte: {file_name_col}, P√°gina: {page})" if page is not None else f" (Fonte: {file_name_col})"
            
            context += item.get('content', '') + source + "\n\n---\n\n"
    else:
        return "Desculpe, a busca vetorial n√£o encontrou contexto relevante nos volumes indexados."


    # 3. CHAMADA AO MODELO (Usando o cliente puro do Google)
    prompt = ChatPromptTemplate.from_messages([
        ("system", "Voc√™ √© um assistente de estudo b√≠blico. Use o CONTEXTO fornecido para responder √† PERGUNTA. Se a resposta n√£o estiver no contexto, diga 'CONTEXTO N√ÉO ENCONTRADO'. Inclua as fontes (P√°gina e Arquivo) no final de cada resposta."),
        ("user", "CONTEXTO: {context}\n\nPERGUNTA: {question}")
    ])
    
    prompt_formatted = prompt.format(context=context, question=query)
    
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt_formatted
        )
        return response.text
    except APIError as e:
        return f"Erro na API do Google ao gerar a resposta: {e}"


# --------------------------------------------------------------------------
# 4. INTERFACE STREAMLIT
# --------------------------------------------------------------------------
st.set_page_config(page_title="Enciclop√©dia B√≠blica RAG", layout="wide")
st.title("üìö Caf√© com Biblia")
st.markdown("Fa√ßa uma pergunta ou deixe uma refer√™ncia biblica.")

# Coluna para a entrada do usu√°rio
user_query = st.text_area("Sua Pergunta de Estudo B√≠blico:", key="query_input")

if st.button("Buscar Resposta", use_container_width=True):
    if user_query:
        with st.spinner("Buscando e analisando o contexto nos 13 volumes..."):
            # Chama a fun√ß√£o principal
            answer = ask_rag(user_query)
        
        # Exibe a resposta formatada
        st.subheader("Resposta da Enciclop√©dia:")
        st.markdown(answer)
    else:
        st.warning("Por favor, digite uma pergunta.")
